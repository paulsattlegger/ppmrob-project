{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "831ac8c1",
   "metadata": {},
   "source": [
    "# Gate Detection\n",
    "\n",
    "[1] <https://pytorch.org/tutorials/intermediate/torchvision_tutorial.html>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebc61f1f",
   "metadata": {},
   "source": [
    "## Defining the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4002f891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "38\n",
      "(<PIL.Image.Image image mode=RGB size=960x720 at 0x7F3A19348670>, {'boxes': tensor([[251.7500, 154.1200, 561.7500, 385.0600]]), 'labels': tensor([1]), 'image_id': tensor([0]), 'area': tensor([71591.3984]), 'iscrowd': tensor([0])})\n",
      "(<PIL.Image.Image image mode=RGB size=960x720 at 0x7F3A19348700>, {'boxes': tensor([[178.8000, 140.4200, 729.9100, 602.6400]]), 'labels': tensor([1]), 'image_id': tensor([1]), 'area': tensor([254734.0781]), 'iscrowd': tensor([0])})\n",
      "(<PIL.Image.Image image mode=RGB size=960x720 at 0x7F3A19348250>, {'boxes': tensor([[369.7500, 272.5600, 784.0500, 690.6600]]), 'labels': tensor([2]), 'image_id': tensor([14]), 'area': tensor([173218.8125]), 'iscrowd': tensor([0])})\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "class TelloDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base, transforms=None):\n",
    "        self.base = Path(base)\n",
    "        tree = ET.parse(self.base / \"annotations.xml\")\n",
    "        self.annotations = tree.getroot()\n",
    "        self.labels = {\n",
    "            \"front\": 1,\n",
    "            \"back\": 2,\n",
    "        }\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def _image(self, index):\n",
    "        element = self.annotations.find(f\"image[{index + 1}]\")\n",
    "        if element:\n",
    "            return Image.open(self.base / \"images\" / element.get(\"name\")).convert(\"RGB\")\n",
    "        raise KeyError(index)\n",
    "\n",
    "    def _box(self, index):\n",
    "        element = self.annotations.find(f\"image[{index + 1}]/box\")\n",
    "        return [\n",
    "            float(element.get(attribute)) for attribute in [\"xtl\", \"ytl\", \"xbr\", \"ybr\"]\n",
    "        ]\n",
    "\n",
    "    def _label(self, index):\n",
    "        element = self.annotations.find(f\"image[{index + 1}]/box\")\n",
    "        label = element.get(\"label\")\n",
    "        return self.labels[label]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get image\n",
    "        image = self._image(index)\n",
    "\n",
    "        # get bounding box coordinates\n",
    "        box = self._box(index)\n",
    "\n",
    "        # get label\n",
    "        label = self._label(index)\n",
    "\n",
    "        # convert everything into a torch.Tensor\n",
    "        boxes = torch.as_tensor([box], dtype=torch.float32)\n",
    "        labels = torch.as_tensor([label], dtype=torch.int64)\n",
    "        image_id = torch.tensor([index])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        iscrowd = torch.zeros((1,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image, target = self.transforms(image, target)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(list(self.annotations.iter(\"image\")))\n",
    "\n",
    "\n",
    "dataset = TelloDataset(\"data/train\")\n",
    "dataset_test = TelloDataset(\"data/test\")\n",
    "\n",
    "print(len(dataset))\n",
    "print(len(dataset_test))\n",
    "print(dataset[0])\n",
    "print(dataset[1])\n",
    "print(dataset[14])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4e0146",
   "metadata": {},
   "source": [
    "## Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be3d517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [ 0/47]  eta: 0:00:48  lr: 0.000114  loss: 1.6247 (1.6247)  loss_classifier: 1.3354 (1.3354)  loss_box_reg: 0.1590 (0.1590)  loss_objectness: 0.1275 (0.1275)  loss_rpn_box_reg: 0.0028 (0.0028)  time: 1.0302  data: 0.3732  max mem: 6749\n"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "import transforms as T\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.PILToTensor())\n",
    "    transforms.append(T.ConvertImageDtype(torch.float))\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "def get_model(num_classes):\n",
    "    # load a model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # train on the GPU or on the CPU, if a GPU is not available\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    # our dataset has three classes - background, front and back\n",
    "    num_classes = 3  # use our dataset and defined transformations\n",
    "\n",
    "    # define training and validation data loaders\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        TelloDataset(\"data/train\", get_transform(train=True)),\n",
    "        batch_size=2,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        collate_fn=utils.collate_fn,\n",
    "    )\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        TelloDataset(\"data/test\", get_transform(train=False)),\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        collate_fn=utils.collate_fn,\n",
    "    )\n",
    "\n",
    "    # get the model using our helper function\n",
    "    model = get_model(num_classes)\n",
    "\n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    # let's train it for 10 epochs\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    print(\"That's it!\")\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
